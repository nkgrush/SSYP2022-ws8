{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LogisticReg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class LogisticRegression(object):\n",
        "    def __init__(self, l1_coef, l2_coef):\n",
        "        self.l1_coef = l1_coef\n",
        "        self.l2_coef = l2_coef\n",
        "        self.w = None\n",
        "    \n",
        "    def fit(self, X, y, epochs=10, lr=0.1, batch_size=100):\n",
        "        n, k = X.shape        \n",
        "        if self.w is None:\n",
        "            np.random.seed(42)\n",
        "            self.w = np.random.randn(k + 1)\n",
        "\n",
        "        X_train = np.concatenate((np.ones((n, 1)), X), axis=1)\n",
        "        \n",
        "        losses = []\n",
        "\n",
        "        for i in range(epochs):\n",
        "            for X_batch, y_batch in self.generate_batches(X_train, y, batch_size):\n",
        "                p = self._predict_proba(X_batch)\n",
        "                losses.append(self._get_loss(y_batch, p))\n",
        "                grad = self.get_grad(X_batch, y_batch, p)\n",
        "                self.w -= X_batch.T @ (p - y_batch) / len(X_batch)\n",
        "        return losses\n",
        "    \n",
        "    def get_grad(self, X_batch, y_batch, predictions):\n",
        "\n",
        "        grad_basic = X_batch.T @ (predictions - y_batch) / len(X_batch)\n",
        "        return grad_basic\n",
        "        \n",
        "    def predict_proba(self, X):\n",
        "        n, k = X.shape\n",
        "        X_ = np.concatenate((np.ones((n, 1)), X), axis=1)\n",
        "        return self.sigmoid(np.dot(X_, self.w))\n",
        "\n",
        "    def _predict_proba(self, X): \n",
        "        return self.sigmoid(np.dot(X, self.w))\n",
        "\n",
        "    def predict(self, X, threshold=0.5):\n",
        "        return self.predict_proba(X) >= threshold\n",
        "\n",
        "    def sigmoid(h):\n",
        "        return 1. / (1 + np.exp(-h))\n",
        " \n",
        "    def _get_loss(self, y, p):  \n",
        "        p = np.clip(p, 1e-10, 1 - 1e-10)\n",
        "        return -np.sum(y * np.log(p) + (1 - y) * np.log(1 - p))\n",
        "\n",
        "    def accuracy(y_pred, y):\n",
        "        return sum(y_pred == y) / len(y)\n",
        "\n",
        "    def generate_batches(X, y, batch_size):\n",
        "        assert len(X) == len(y)\n",
        "        np.random.seed(42)\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "        \n",
        "        perm =  np.random.permutation(len(X))\n",
        "        \n",
        "        for i in range(len(perm) // batch_size):\n",
        "            idx = perm[i*batch_size:(i+1)*batch_size]\n",
        "            curr_x = X[idx]\n",
        "            curr_y = y[idx]\n",
        "            yield curr_x, curr_y"
      ],
      "metadata": {
        "id": "ajaaSwVw69ju"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}