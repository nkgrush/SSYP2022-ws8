{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1TTHJARJLwSE"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "\n",
        "class RNNCell(nn.Module):\n",
        "    def __init__(self, input_dim, hid_dim, device='cpu'):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.state2hid = nn.Linear(input_dim + hid_dim, hid_dim)\n",
        "        self.state2out = nn.Linear(input_dim + hid_dim, hid_dim)\n",
        "        self.act = nn.Sigmoid()\n",
        "        self.hid_dim = hid_dim\n",
        "        self.device = device\n",
        "\n",
        "    def forward_once(self, input, hidden):\n",
        "        concat = torch.cat((input, hidden), 1)\n",
        "        concat = self.act(concat)\n",
        "        next_hid = self.state2hid(concat)\n",
        "        next_out = self.state2out(concat)\n",
        "\n",
        "        return next_out, next_hid\n",
        "\n",
        "    def forward(self, input_batch, hidden=None):\n",
        "        hid_list = []\n",
        "        out_list = []\n",
        "        if hidden is None:\n",
        "            hidden = self.initHidden(input_batch.shape[1])\n",
        "            \n",
        "        for word_batch_input in input_batch:\n",
        "            next_out, next_hid = self.forward_once(word_batch_input, hidden)\n",
        "            hid_list.append(next_hid)\n",
        "            out_list.append(next_out)\n",
        "            hidden = next_hid\n",
        "            \n",
        "        return torch.stack(out_list), torch.stack(hid_list)\n",
        "\n",
        "    def initHidden(self, batch_size):\n",
        "        return nn.init.kaiming_uniform_(torch.empty(batch_size, self.hid_dim)).to(self.device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, classes, input_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        hid_dim = 4\n",
        "        self.emb = nn.Embedding(vocab_size, input_dim)\n",
        "        self.rnn_cell = RNNCell(input_dim, hid_dim)\n",
        "        self.fc = nn.Linear(hid_dim, classes)\n",
        "        \n",
        "    def forward(self, x, original_lens):\n",
        "        x = self.emb(x)\n",
        "\n",
        "        out, hid = self.rnn_cell(x)\n",
        "        print(out.shape)\n",
        "        last_out = out[-1]\n",
        "        x = self.fc(last_out)\n",
        "        return x"
      ],
      "metadata": {
        "id": "PEPjOBAsL0i9"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}